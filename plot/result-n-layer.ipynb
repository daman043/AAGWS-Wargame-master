{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "file_head = '../Baselines/EnemyPositionPrediction/checkpoints'\n",
    "CNN_GRU_5_1_result = '/CNN_GRU_5_1/all/test/test_result'\n",
    "CNN_GRU_5_2_result = '/CNN_GRU_5_2/all/test/test_result'\n",
    "CNN_GRU_7_1_result = '/CNN_GRU_7_1/all/test/test_result'\n",
    "# CNN_GRU_7_2_result = '/CNN_GRU_7_2/all/test/test_result'\n",
    "CNN_GRU_9_1_result = '/CNN_GRU_9_1/all/test/test_result'\n",
    "with open(file_head + CNN_GRU_5_1_result,'rb') as f:\n",
    "    CNN_GRU_5_1_file = pickle.load(f)\n",
    "with open(file_head + CNN_GRU_5_2_result,'rb') as f:\n",
    "    CNN_GRU_5_2_file = pickle.load(f)\n",
    "# with open(file_head + CNN_GRU_7_1_result,'rb') as f:\n",
    "#     Res_tensor_vector_result_file = pickle.load(f)\n",
    "with open(file_head + CNN_GRU_7_2_result,'rb') as f:\n",
    "    CNN_GRU_7_2_file = pickle.load(f)\n",
    "with open(file_head + CNN_GRU_9_1_result,'rb') as f:\n",
    "    CNN_GRU_9_1_file = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_acc(result_file, offset=0):\n",
    "    acc_n = []\n",
    "    for dic in result_file:\n",
    "        acc = [[] for _ in range(7)]\n",
    "        for piece in range(6):\n",
    "            action_pre=dic['action_pre_per_replay'][piece]\n",
    "            action_gt = dic['action_gt_per_replay'][piece]\n",
    "            for action_pre_per_replay, action_gt_per_replay in zip(action_pre, action_gt):\n",
    "                acc_per_replay = np.mean(action_pre_per_replay[offset:] == action_gt_per_replay[offset:])\n",
    "                acc[piece].append(acc_per_replay)\n",
    "\n",
    "        for piece in range(6):\n",
    "            acc[piece] = np.array(acc[piece]).mean()\n",
    "        acc[6] = np.array(acc[:6]).mean()\n",
    "        acc_n.append(acc)\n",
    "    acc_n = np.array(acc_n)    \n",
    "    max_row = np.argmax(acc_n[:,-1])\n",
    "    ##################################\n",
    "    steps = 10\n",
    "    dic_max = result_file[max_row]\n",
    "    \n",
    "    acc_n_step = []\n",
    "    action_pre_result, action_gt_result = [[] for _ in range(steps)], [[] for _ in range(steps)]\n",
    "    for piece in range(6):\n",
    "        action_pre = dic_max['action_pre_per_replay'][piece]\n",
    "        action_gt = dic_max['action_gt_per_replay'][piece]\n",
    "        for action_pre_per_replay, action_gt_per_replay in zip(action_pre, action_gt):\n",
    "            if len(action_pre_per_replay[offset:]) < steps:\n",
    "                continue\n",
    "\n",
    "            step = len(action_pre_per_replay[offset:]) // steps\n",
    "            for s in range(steps):\n",
    "                action_pre_result[s].append(action_pre_per_replay[offset:][s * step:(s + 1) * step])\n",
    "                action_gt_result[s].append(action_gt_per_replay[offset:][s * step:(s + 1) * step])\n",
    "\n",
    "        X = np.arange(steps)\n",
    "        Y = np.zeros(steps)\n",
    "        for idx, (action_pres, action_gts) in enumerate(zip(action_pre_result, action_gt_result)):\n",
    "\n",
    "            action_pres_np = np.hstack(action_pres)\n",
    "            action_gts_np = np.hstack(action_gts)\n",
    "\n",
    "            Y[idx] = np.mean(action_pres_np == action_gts_np)\n",
    "        acc_n_step.append(Y)\n",
    "    return acc_n[max_row, :], np.array(acc_n_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2799726  0.26349458 0.29117176 0.27810336 0.36723264 0.35539351\n",
      " 0.30589474] [0.26850221 0.24133785 0.28593288 0.27097649 0.37553874 0.35156581\n",
      " 0.29897566] [0.29999548 0.25379487 0.289165   0.2711406  0.36857819 0.34493772\n",
      " 0.30460198] [0.30341162 0.27243758 0.28257847 0.25808266 0.37757332 0.30395573\n",
      " 0.29967323]\n"
     ]
    }
   ],
   "source": [
    "CNN_GRU_5_1_acc_max, CNN_GRU_5_1_acc_n_step = get_max_acc(CNN_GRU_5_1_file, offset=0)\n",
    "CNN_GRU_5_2_acc_max, CNN_GRU_5_2_acc_n_step = get_max_acc(CNN_GRU_5_2_file, offset=0)\n",
    "# Res_tensor_vector_acc_max, Res_tensor_vector_acc_n_step = get_max_acc(Res_tensor_vector_result_file, offset=9)\n",
    "CNN_GRU_7_2_acc_max, CNN_GRU_7_2_acc_n_step = get_max_acc(CNN_GRU_7_2_file, offset=0)\n",
    "CNN_GRU_9_1_acc_max, CNN_GRU_9_1_acc_n_step = get_max_acc(CNN_GRU_9_1_file, offset=0)\n",
    "\n",
    "# print(Res_tensor_acc_n_step)\n",
    "print(CNN_GRU_5_1_acc_max, CNN_GRU_5_2_acc_max, CNN_GRU_7_2_acc_max, CNN_GRU_9_1_acc_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  2  6 12]\n",
      "  [ 4 10 18 28]]\n",
      "\n",
      " [[ 8 18 30 44]\n",
      "  [12 26 42 60]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(16).reshape(2,2,4)\n",
    "b = np.array([1,2,3,4])\n",
    "print(b*a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
